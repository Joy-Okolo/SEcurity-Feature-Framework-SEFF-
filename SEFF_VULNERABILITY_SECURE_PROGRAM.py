import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
import numpy as np
from sklearn.metrics import classification_report

# Load the dataset
data = pd.read_csv(r"C:\Users\Admin\Desktop\MY STUFFS\CS 710\Project materials\vulnerability_dataset.csv",
                   delimiter=';')

# Clean column names and remove quotes
data.columns = data.columns.str.replace('"', '')  # Remove quotes from column names
data = data.apply(lambda col: col.str.replace('"', '') if col.dtypes == 'object' else col)  # Clean string values

# Encode categorical columns
encoder_language = LabelEncoder()
data['language'] = encoder_language.fit_transform(data['language'])  # Encode language

encoder_vulnerability = LabelEncoder()
data['vulnerability_type'] = encoder_vulnerability.fit_transform(
    data['vulnerability_type'])  # Encode vulnerability type

encoder_seff = LabelEncoder()
data['seff_criteria'] = encoder_seff.fit_transform(data['seff_criteria'])  # Encode SEFF criteria

data['label'] = data['label'].map({'vulnerable': 0, 'secure': 1})  # Map label to binary values


# Feature Extraction
def extract_sensitive_data_features(code):
    """Extract features specific to Sensitive Data Exposure."""
    return {
        'contains_password': "password" in code.lower(),
        'contains_api_key': "api_key" in code.lower(),
        'contains_token': "token" in code.lower(),
        'uses_unencrypted_http': "http://" in code.lower()
    }


# Extract Sensitive Data Exposure features
sensitive_features = pd.DataFrame([extract_sensitive_data_features(code) for code in data['code_sample']])
tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))
tfidf_features = tfidf_vectorizer.fit_transform(data['code_sample'])

# Combine TF-IDF features with sensitive-specific features
combined_features = np.hstack([tfidf_features.toarray(), sensitive_features.values])
labels = data['label'].values

# Balance the dataset using SMOTE
smote = SMOTE(random_state=42)
features_balanced, labels_balanced = smote.fit_resample(combined_features, labels)

# Train-test split for vulnerability detection
X_train, X_test, y_train, y_test = train_test_split(features_balanced, labels_balanced, test_size=0.2, random_state=42)

# Train-test split for vulnerability type classification
vuln_type_features = np.hstack([tfidf_features.toarray(), sensitive_features.values])
X_train_vt, X_test_vt, y_train_vt, y_test_vt = train_test_split(
    vuln_type_features, data['vulnerability_type'], test_size=0.2, random_state=42
)

# Train-test split for SEFF criteria classification
X_train_seff, X_test_seff, y_train_seff, y_test_seff = train_test_split(
    combined_features, data['seff_criteria'], test_size=0.2, random_state=42
)

# Train models
rf_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)  # For secure/vulnerable detection
rf_model.fit(X_train, y_train)

vuln_type_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)  # For vulnerability type
vuln_type_model.fit(X_train_vt, y_train_vt)

seff_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)  # For SEFF criteria
seff_model.fit(X_train_seff, y_train_seff)


# Function to analyze a single code snippet
def analyze_code(new_code, language):
    try:
        # Preprocess the input code
        new_code_features = tfidf_vectorizer.transform([new_code]).toarray()
        sensitive_specific_features = pd.DataFrame([extract_sensitive_data_features(new_code)]).values
        combined_features = np.hstack([new_code_features, sensitive_specific_features])

        # Encode the language
        encoded_language = encoder_language.transform([language])[0]

        # Predict whether the code is secure or vulnerable
        vulnerability_prediction = rf_model.predict(combined_features)[0]

        # Predict the vulnerability type
        vuln_type_prediction = vuln_type_model.predict(combined_features)[0]
        vulnerability_type = encoder_vulnerability.inverse_transform([vuln_type_prediction])[0]

        # Predict the SEFF criteria issue
        seff_prediction = seff_model.predict(combined_features)[0]
        seff_issue = encoder_seff.inverse_transform([seff_prediction])[0]

        # Provide feedback
        if vulnerability_prediction == 0:  # Vulnerable
            print(f"\nThe code is identified as **VULNERABLE**.")
            print(f"Detected Vulnerability Type: **{vulnerability_type}**")
            print(f"The issue is related to SEFF Criteria: **{seff_issue}**.")

            if seff_issue == "Sensitive Data Exposure":
                print("- Avoid hardcoding sensitive information like passwords, API keys, or tokens.")
                print("- Use encrypted protocols (e.g., HTTPS) for communication.")
        else:  # Secure
            print(f"\nThe code is identified as **SECURE**.")
            print("**Great job!** Keep following secure coding practices.")
    except Exception as e:
        print(f"An error occurred during analysis: {e}")


# User Input
print("Enter the details for the code snippet you'd like to analyze:")
new_code = input("Enter your code snippet (multi-line supported):\n")
language = input("Enter the programming language (e.g., Python, Java, C++): ")

# Validate language
if language not in encoder_language.classes_:
    print("Error: Invalid programming language.")
else:
    # Analyze the code
    analyze_code(new_code, language)
